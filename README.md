# Rede Neural Artificial usando apenas Numpy
### Construída a partir do conhecimento obtido na Pós Graduação em Inteligência Artificial

O arquivo `activation.py` contém as funções de ativação e suas derivadas responsáveis pelo cálculo do gradiente descendente.  
**Funções de ativação**
- Sigmoid;
- Tangente Hiperbólica (tanh);
- ReLU (Rectified Linear Units).

O arquivo `fit.py` contém as funções para normalização dos dados.  
O arquivo `nn.py` contém a construção da Rede Neural Artificial.  
O arquivo `test.py` é uma demonstração do funcionamento da rede.
